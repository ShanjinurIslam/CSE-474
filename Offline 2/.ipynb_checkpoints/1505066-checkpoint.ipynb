{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(filename):\n",
    "    df = pd.read_csv(filename,delimiter='\\s+',header=None)\n",
    "    X = df[df.columns[:-1]].values\n",
    "    y = df[df.columns[-1]].values\n",
    "    \n",
    "    num_classes = len(np.unique(y))\n",
    "    N = len(X)\n",
    "    \n",
    "    Y = np.zeros((N,num_classes))\n",
    "    \n",
    "    for i in range(N):\n",
    "        Y[i][y[i]-1] = 1\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train = generate('trainNN.txt')\n",
    "X_test, Y_test  =  generate('testNN.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "class L_Layer_NN:\n",
    "    def __init__(self,L,k,learning_rate = 0.5):\n",
    "        self.L = L\n",
    "        self.k = k\n",
    "        self.W = []\n",
    "        self.W.append(0)\n",
    "        self.lr = learning_rate\n",
    "        self.k = np.insert(self.k,0,values=0,axis=0)\n",
    "        print(self.k)\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "\n",
    "    def derivative(self,z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "    \n",
    "    def fit(self,X_train,Y_train,max_epoch=1000):\n",
    "        N = len(X_train)\n",
    "        \n",
    "        self.k[0] = X_train.shape[1]\n",
    "        \n",
    "        for r in range(0,self.L):\n",
    "            random_weight = np.random.uniform(0,1,size=(self.k[r+1],self.k[r]+1))\n",
    "            random_weight = np.insert(random_weight,0,values=0,axis=0)\n",
    "            self.W.append(random_weight)\n",
    "                    \n",
    "        X_train = np.insert(X_train,0,values=1,axis=1)\n",
    "        Y_train = np.insert(Y_train,0,values=0,axis=1)\n",
    "        \n",
    "        for epoch in range(max_epoch):\n",
    "            y_m = []\n",
    "            J = 0\n",
    "            \n",
    "            for i in range(N):\n",
    "                x_i = X_train[i]\n",
    "                \n",
    "                y = []\n",
    "                y.append(x_i)\n",
    "                \n",
    "                v = []\n",
    "                v.append(0)\n",
    "                \n",
    "                for r in range(1,self.L+1):\n",
    "                    v_r = np.dot(np.array(self.W[r][1:]),np.array(y[r-1]))\n",
    "                    y_r = self.sigmoid(v_r)\n",
    "                    v_r = np.insert(v_r,0,values=0,axis=0)\n",
    "                    y_r = np.insert(y_r,0,values=1,axis=0)\n",
    "                        \n",
    "                    v.append(v_r)\n",
    "                    y.append(y_r)\n",
    "                    \n",
    "                \n",
    "                J += 0.5*np.sum((y[self.L][1:]-Y_train[i][1:])**2,axis=0)\n",
    "                   \n",
    "                delta_L = np.multiply((y[self.L][1:]-Y_train[i][1:]),self.derivative(v[self.L][1:]))\n",
    "                delta_L = np.insert(delta_L,0,values=0,axis=0)\n",
    "                \n",
    "                delta = []\n",
    "                delta.append(0)\n",
    "                \n",
    "                for r in range(1,self.L+1):\n",
    "                    if r == self.L :\n",
    "                        delta.append(delta_L)\n",
    "                    else:\n",
    "                        temp = np.zeros(self.k[r]+1)\n",
    "                        delta.append(temp)\n",
    "                        \n",
    "                \n",
    "                for r in range(self.L,1,-1):\n",
    "                    for j in range(1,self.k[r-1]+1):\n",
    "                        e_j = 0\n",
    "                        for k in range(1,self.k[r]+1):\n",
    "                            e_j += delta[r][k]*self.W[r][k][j]\n",
    "                        delta[r-1][j] = e_j*self.derivative(v[r-1][j])\n",
    "                    \n",
    "                for r in range(1,self.L+1):\n",
    "                    for j in range(1,self.k[r]+1):\n",
    "                        del_w = -self.lr*np.multiply(y[r-1],delta[r][j])\n",
    "                        self.W[r][j] = self.W[r][j] + del_w\n",
    "            \n",
    "                \n",
    "            print(\"Epoch \" + str(epoch) + \", Cost \" + str(J))\n",
    "            if J < 10:\n",
    "                break\n",
    "            \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def predict(self,X,Y):\n",
    "        X = np.insert(X,0,values=1,axis=1)\n",
    "        Y = np.insert(Y,0,values=0,axis=1)\n",
    "        \n",
    "        N = len(X)\n",
    "        true = 0\n",
    "        \n",
    "        for i in range(N):\n",
    "            x_i = X[i]\n",
    "                \n",
    "            y = []\n",
    "            y.append(x_i)\n",
    "                \n",
    "            for r in range(1,self.L+1):\n",
    "                y_r = []\n",
    "                y_r.append(1)\n",
    "                for j in range(1,self.k[r]+1):\n",
    "                    dot_product = np.dot(np.array(self.W[r][j]),np.array(y[r-1]))\n",
    "                    y_r.append(self.sigmoid(dot_product))\n",
    "                        \n",
    "                y.append(y_r)\n",
    "            \n",
    "            \n",
    "            if np.argmax(y[self.L][1:]) == np.argmax(Y[i][1:]):\n",
    "                true += 1\n",
    "                \n",
    "        return true/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 5 3 2 4]\n",
      "Epoch 0, Cost 198.12072131929958\n",
      "Epoch 1, Cost 192.12914465726752\n",
      "Epoch 2, Cost 191.85069926772928\n",
      "Epoch 3, Cost 191.77866562095562\n",
      "Epoch 4, Cost 191.74817241291822\n",
      "Epoch 5, Cost 191.73183936817472\n",
      "Epoch 6, Cost 191.72181578723348\n",
      "Epoch 7, Cost 191.71509660926253\n",
      "Epoch 8, Cost 191.71030564608472\n",
      "Epoch 9, Cost 191.70673044192537\n",
      "Epoch 10, Cost 191.7039676965019\n",
      "Epoch 11, Cost 191.7017730441608\n",
      "Epoch 12, Cost 191.6999902749319\n",
      "Epoch 13, Cost 191.69851511729593\n",
      "Epoch 14, Cost 191.69727544089542\n",
      "Epoch 15, Cost 191.69621983323776\n",
      "Epoch 16, Cost 191.6953107038091\n",
      "Epoch 17, Cost 191.69451995877796\n",
      "Epoch 18, Cost 191.69382619737303\n",
      "Epoch 19, Cost 191.6932128419709\n",
      "Epoch 20, Cost 191.69266685933817\n",
      "Epoch 21, Cost 191.6921778665862\n",
      "Epoch 22, Cost 191.69173749367366\n",
      "Epoch 23, Cost 191.69133892074962\n",
      "Epoch 24, Cost 191.69097653700808\n",
      "Epoch 25, Cost 191.69064568549393\n",
      "Epoch 26, Cost 191.6903424696827\n",
      "Epoch 27, Cost 191.69006360512398\n",
      "Epoch 28, Cost 191.68980630438048\n",
      "Epoch 29, Cost 191.68956818689472\n",
      "Epoch 30, Cost 191.6893472077117\n",
      "Epoch 31, Cost 191.68914160062795\n",
      "Epoch 32, Cost 191.68894983247807\n",
      "Epoch 33, Cost 191.68877056609975\n",
      "Epoch 34, Cost 191.68860263012436\n",
      "Epoch 35, Cost 191.68844499416412\n",
      "Epoch 36, Cost 191.68829674831585\n",
      "Epoch 37, Cost 191.68815708612618\n",
      "Epoch 38, Cost 191.6880252903578\n",
      "Epoch 39, Cost 191.6879007210366\n",
      "Epoch 40, Cost 191.68778280536284\n",
      "Epoch 41, Cost 191.68767102916036\n",
      "Epoch 42, Cost 191.68756492959378\n",
      "Epoch 43, Cost 191.6874640889419\n",
      "Epoch 44, Cost 191.68736812925363\n",
      "Epoch 45, Cost 191.68727670774396\n",
      "Epoch 46, Cost 191.68718951281255\n",
      "Epoch 47, Cost 191.68710626059053\n",
      "Epoch 48, Cost 191.6870266919337\n",
      "Epoch 49, Cost 191.68695056979757\n",
      "Epoch 50, Cost 191.68687767694206\n",
      "Epoch 51, Cost 191.6868078139106\n",
      "Epoch 52, Cost 191.68674079725454\n",
      "Epoch 53, Cost 191.68667645796538\n",
      "Epoch 54, Cost 191.6866146400853\n",
      "Epoch 55, Cost 191.6865551994759\n",
      "Epoch 56, Cost 191.6864980027254\n",
      "Epoch 57, Cost 191.68644292616938\n",
      "Epoch 58, Cost 191.6863898550214\n",
      "Epoch 59, Cost 191.6863386825938\n",
      "Epoch 60, Cost 191.68628930959602\n",
      "Epoch 61, Cost 191.6862416435096\n",
      "Epoch 62, Cost 191.68619559801945\n",
      "Epoch 63, Cost 191.68615109250615\n",
      "Epoch 64, Cost 191.68610805158517\n",
      "Epoch 65, Cost 191.68606640468968\n",
      "Epoch 66, Cost 191.68602608569245\n",
      "Epoch 67, Cost 191.68598703256436\n",
      "Epoch 68, Cost 191.68594918706327\n",
      "Epoch 69, Cost 191.68591249444802\n",
      "Epoch 70, Cost 191.68587690322246\n",
      "Epoch 71, Cost 191.68584236489832\n",
      "Epoch 72, Cost 191.6858088337786\n",
      "Epoch 73, Cost 191.6857762667622\n",
      "Epoch 74, Cost 191.6857446231607\n",
      "Epoch 75, Cost 191.68571386453377\n",
      "Epoch 76, Cost 191.6856839545361\n",
      "Epoch 77, Cost 191.68565485877662\n",
      "Epoch 78, Cost 191.68562654469008\n",
      "Epoch 79, Cost 191.68559898141677\n",
      "Epoch 80, Cost 191.6855721396938\n",
      "Epoch 81, Cost 191.68554599175312\n",
      "Epoch 82, Cost 191.68552051122634\n",
      "Epoch 83, Cost 191.68549567305985\n",
      "Epoch 84, Cost 191.68547145343314\n",
      "Epoch 85, Cost 191.68544782968405\n",
      "Epoch 86, Cost 191.6854247802383\n",
      "Epoch 87, Cost 191.68540228454842\n",
      "Epoch 88, Cost 191.68538032303022\n",
      "Epoch 89, Cost 191.68535887700838\n",
      "Epoch 90, Cost 191.68533792866492\n",
      "Epoch 91, Cost 191.6853174609903\n",
      "Epoch 92, Cost 191.68529745773802\n",
      "Epoch 93, Cost 191.6852779033831\n",
      "Epoch 94, Cost 191.68525878308145\n",
      "Epoch 95, Cost 191.68524008263412\n",
      "Epoch 96, Cost 191.68522178845254\n",
      "Epoch 97, Cost 191.6852038875248\n",
      "Epoch 98, Cost 191.6851863673885\n",
      "Epoch 99, Cost 191.68516921609847\n"
     ]
    }
   ],
   "source": [
    "output_neurons = Y_train.shape[1] \n",
    "\n",
    "model = L_Layer_NN(4,[5,3,2,output_neurons],learning_rate=1)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()  # min max scaler\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "model.fit(X_train,Y_train,max_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.264"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.256"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
