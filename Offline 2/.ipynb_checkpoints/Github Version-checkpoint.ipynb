{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_function(x):\n",
    "    try:\n",
    "        ans = 1.0 / (1 + math.exp(-x))\n",
    "    except OverflowError:\n",
    "        if x > 0:\n",
    "            ans = 1\n",
    "        elif x == 0:\n",
    "            ans = 0.5\n",
    "        else:\n",
    "            ans = 0\n",
    "    return ans\n",
    "\n",
    "\n",
    "def logistic_function_bar(x):\n",
    "    return logistic_function(x)*(1 - logistic_function(x))\n",
    "\n",
    "\n",
    "def relu_func(x):\n",
    "    if x < 0:\n",
    "        return 0.01*x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def relu_func_bar(x):\n",
    "    if x < 0:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def func3(x):\n",
    "    return math.tanh(x/2.0)\n",
    "\n",
    "\n",
    "def func3_bar(x):\n",
    "    return 0.5*(1 - func3(x)*func3(x))\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, num_of_layers, node_counts, activation_function, activation_function_der, num_of_features):\n",
    "        # num_of_layers = hidden + output\n",
    "        # node_counts = number of nodes in every layer including output layer (num of classes)\n",
    "        self.nof = num_of_features\n",
    "        self.w = []\n",
    "        self.nol = num_of_layers\n",
    "        self.node_counts = node_counts\n",
    "        self.af = activation_function\n",
    "        self.daf = activation_function_der\n",
    "        self.u = 1\n",
    "\n",
    "        self.class_vectors = [[]]\n",
    "\n",
    "        self.k = [num_of_features]\n",
    "\n",
    "        for nc in node_counts:\n",
    "            self.k.append(nc)\n",
    "\n",
    "        self.w.append([])  # dummy append to start the index from 1\n",
    "\n",
    "        for r in range(1, num_of_layers + 1):\n",
    "            self.w.append([])\n",
    "            self.w[r].append([])  # dummy append to start the index from 1\n",
    "            for j in range(1, self.k[r] + 1):\n",
    "                self.w[r].append([])\n",
    "                for k in range(self.k[r - 1] + 1):\n",
    "                    self.w[r][j].append(random.uniform(0, 1))\n",
    "\n",
    "        for i in range(1, self.k[num_of_layers] + 1):\n",
    "            self.class_vectors.append([0]*(self.k[num_of_layers] + 1))\n",
    "            self.class_vectors[i][i] = 1\n",
    "            \n",
    "        print(self.w)\n",
    "\n",
    "    def train(self, features, labels):\n",
    "        N = features.shape[0]\n",
    "\n",
    "        ym = []\n",
    "\n",
    "        for i in range(0, N):\n",
    "            ym.append(self.class_vectors[labels.iloc[i]])\n",
    "\n",
    "        temp = [1]*N\n",
    "\n",
    "        x = pd.concat([pd.DataFrame(temp), features], axis=1, ignore_index=True)\n",
    "\n",
    "        v = []\n",
    "        y = []\n",
    "        delta = []\n",
    "\n",
    "        for i in range(N):\n",
    "            v.append([])\n",
    "            y.append([])\n",
    "            delta.append([])\n",
    "            y[i].append(x.iloc[i, :].tolist())\n",
    "            for r in range(self.nol + 1):\n",
    "                v[i].append([])\n",
    "                delta[i].append([])\n",
    "                if r > 0:\n",
    "                    y[i].append([])\n",
    "                for j in range(self.k[r] + 1):\n",
    "                    v[i][r].append(0)\n",
    "                    delta[i][r].append(0)\n",
    "                    if r > 0:\n",
    "                        if j == 0:\n",
    "                            y[i][r].append(1)\n",
    "                        else:\n",
    "                            y[i][r].append(0)\n",
    "        \n",
    "        iter_constraint = 0\n",
    "        while True:\n",
    "            iter_constraint += 1\n",
    "            if iter_constraint > 50:\n",
    "                break\n",
    "            for i in range(0, N):\n",
    "                for r in range(1, self.nol + 1):\n",
    "                    for j in range(1, self.k[r] + 1):\n",
    "                        v[i][r][j] = pd.Series(self.w[r][j]).dot(pd.Series(y[i][r - 1]))\n",
    "                        y[i][r][j] = self.af(v[i][r][j])\n",
    "\n",
    "                for j in range(1, self.k[self.nol] + 1):\n",
    "                    err = y[i][self.nol][j] - ym[i][j]\n",
    "                    delta[i][self.nol][j] = err*self.daf(v[i][self.nol][j])\n",
    "\n",
    "                for r in range(self.nol, 1, -1):\n",
    "                    for j in range(1, self.k[r - 1] + 1):\n",
    "                        err = 0\n",
    "                        for k in range(1, self.k[r] + 1):\n",
    "                            err += delta[i][r][k]*self.w[r][k][j]\n",
    "                        delta[i][r - 1][j] = err*self.daf(v[i][r - 1][j])\n",
    "\n",
    "                for r in range(1, self.nol + 1):\n",
    "                    for j in range(1, self.k[r] + 1):\n",
    "                        update = pd.Series(y[i][r - 1]).multiply(delta[i][r][j])\n",
    "                        update = update.multiply(-self.u)\n",
    "                        w_new = pd.Series(self.w[r][j]).add(update)\n",
    "                        self.w[r][j] = w_new.tolist()\n",
    "            J = 0\n",
    "            for i in range(0, N):\n",
    "                ei = 0\n",
    "                for j in range(1, self.k[self.nol] + 1):\n",
    "                    ei += (ym[i][j] - y[i][self.nol][j])*(ym[i][j] - y[i][self.nol][j])\n",
    "                ei *= 0.5\n",
    "                J += ei\n",
    "            print(\"Iteration \" + str(iter_constraint) + \", Cost \" + str(J))\n",
    "            if J < 10:\n",
    "                break\n",
    "\n",
    "    def decide(self, x):\n",
    "        x = pd.concat([pd.Series([1]), x], axis=0, ignore_index=True)\n",
    "        y = [x.tolist()]\n",
    "\n",
    "        for r in range(1, self.nol + 1):\n",
    "            y.append([])\n",
    "            y[r].append(1.0)\n",
    "            for j in range(1, self.k[r] + 1):\n",
    "                v = pd.Series(self.w[r][j]).dot(pd.Series(y[r - 1]))\n",
    "                y[r].append(self.af(v))\n",
    "\n",
    "        max_value_idx = y[self.nol][1:].index(max(y[self.nol][1:]))\n",
    "        return max_value_idx + 1\n",
    "\n",
    "        # for i in range(1, self.k[self.nol] + 1):\n",
    "        #    if self.class_vectors[i][1:] == y[self.nol][1:]:\n",
    "        #       return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [[], [0.9924272423050888, 0.6337283331673697, 0.30723257433384377, 0.9061253147332906, 0.3196133983831767], [0.727022649394206, 0.29037964469179844, 0.9324148738310891, 0.8873849336888244, 0.9731060758740194], [0.9390117532957908, 0.8107422433534368, 0.6359261099132527, 0.8579151182628039, 0.026354447515190893], [0.05577736068071382, 0.17055317678216142, 0.7928911407672176, 0.2903294662521586, 0.16798609836550804]], [[], [0.7099546894027847, 0.10751229730633871, 0.14741561627245825, 0.537829795744963, 0.06188648256547191], [0.7751017364347768, 0.5644801255864988, 0.8927831184201337, 0.1365774166974174, 0.9834889064656145], [0.05590394237656271, 0.8944986362641655, 0.5473837499024965, 0.57846067415853, 0.20012958882416054], [0.9620769885429875, 0.8058986010899408, 0.2721454353642462, 0.45768024826606835, 0.4901089555754927]]]\n",
      "Iteration 1, Cost 167.29272206252105\n",
      "Iteration 2, Cost 88.65448325908888\n",
      "Iteration 3, Cost 48.05665779194374\n",
      "Iteration 4, Cost 18.664746825607406\n",
      "Iteration 5, Cost 7.5663385331512485\n",
      "Time to train 15.54623007774353\n",
      "Accuracy of training data 100.0\n",
      "Accuracy of test data 100.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df = pd.read_csv('trainNN.txt', delimiter='\\s+', header=None)\n",
    "df = pd.read_csv('trainNN.txt', delimiter='\\s+', header=None)\n",
    "\n",
    "X = df.iloc[:, :df.shape[1] - 1]\n",
    "Y = df.iloc[:, df.shape[1] - 1]\n",
    "\n",
    "min_max_scaler = MinMaxScaler()  # min max scaler\n",
    "min_max_scaler.fit(X)\n",
    "X = min_max_scaler.transform(X)\n",
    "\n",
    "print(X)\n",
    "\n",
    "num_of_class = len(Y.unique())\n",
    "\n",
    "start = time.time()\n",
    "mlp = MultiLayerPerceptron(2, [4, num_of_class], logistic_function, logistic_function_bar, X.shape[1])\n",
    "\n",
    "mlp.train(pd.DataFrame(X), Y)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time to train \" + str(end - start))\n",
    "\n",
    "true_res = false_res = 0\n",
    "\n",
    "for rn in range(X.shape[0]):\n",
    "    res = mlp.decide(pd.Series(X[rn, :]))\n",
    "    if res == Y.iloc[rn]:\n",
    "        true_res += 1.0\n",
    "    else:\n",
    "        false_res += 1.0\n",
    "\n",
    "accuracy = true_res/(true_res + false_res)\n",
    "print(\"Accuracy of training data \" + str(accuracy*100))\n",
    "\n",
    "# test_df = pd.read_csv('testNN.txt', delimiter='\\s+', header=None)\n",
    "test_df = pd.read_csv('testNN.txt', delimiter='\\s+', header=None)\n",
    "X = test_df.iloc[:, :test_df.shape[1] - 1]\n",
    "Y = test_df.iloc[:, test_df.shape[1] - 1]\n",
    "\n",
    "X = min_max_scaler.transform(X)\n",
    "\n",
    "for rn in range(X.shape[0]):\n",
    "    res = mlp.decide(pd.Series(X[rn, :]))\n",
    "    if res == Y.iloc[rn]:\n",
    "        true_res += 1.0\n",
    "    else:\n",
    "        false_res += 1.0\n",
    "\n",
    "accuracy = true_res/(true_res + false_res)\n",
    "print(\"Accuracy of test data \" + str(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
