{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(filename):\n",
    "    df = pd.read_csv(filename,delimiter='\\s+',header=None)\n",
    "    X = df[df.columns[:-1]].values\n",
    "    y = df[df.columns[-1]].values\n",
    "    \n",
    "    num_classes = len(np.unique(y))\n",
    "    N = len(X)\n",
    "    \n",
    "    Y = np.zeros((N,num_classes))\n",
    "    \n",
    "    for i in range(N):\n",
    "        Y[i][y[i]-1] = 1\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train = generate('trainNN.txt')\n",
    "X_test, Y_test  =  generate('testNN.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L_Layer_NN():\n",
    "    def __init__(self,k,lr=0.25,max_epoch=1000):\n",
    "        self.k = k\n",
    "        self.L = len(self.k)-1\n",
    "        self.weights = []\n",
    "        self.lr = lr\n",
    "        self.max_epoch = max_epoch\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for i in range(1,len(self.k)):\n",
    "            self.weights.append(np.random.uniform(0,1,(self.k[i],self.k[i-1]+1)))\n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "\n",
    "    def derivative(self,z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "            \n",
    "    def feed_forward(self,x_i):\n",
    "        self.y = []\n",
    "        self.v = []\n",
    "        \n",
    "        self.y.append(x_i)\n",
    "        \n",
    "        for r in range(self.L):\n",
    "            v_r = np.dot(self.weights[r],self.y[r])\n",
    "            self.v.append(v_r)\n",
    "            y_r = self.sigmoid(v_r)\n",
    "            y_r = np.insert(y_r,0,values=1,axis=0)\n",
    "            self.y.append(y_r)\n",
    "    \n",
    "    def backpropagation(self,y_true):\n",
    "        self.delta = [0]*self.L\n",
    "        self.y_hat = self.y[-1]\n",
    "        self.delta[self.L-1] = np.multiply(self.y_hat[1:]-y_true,self.derivative(self.v[self.L-1]))    \n",
    "        \n",
    "        for r in reversed(range(0,self.L-1)):\n",
    "            e_r = np.dot(self.delta[r+1],self.weights[r+1][:,1:])\n",
    "            self.delta[r] = np.multiply(e_r,self.derivative(self.v[r]))\n",
    "    \n",
    "    def update_weights(self):\n",
    "        self.y = self.y[:-1]\n",
    "        for r in range(self.L):\n",
    "            self.weights[r] = self.weights[r] - self.lr*((self.delta[r].reshape(-1,1))*self.y[r])\n",
    "    \n",
    "    def calculate_cost(self,y_hat,y_true):\n",
    "        return 0.5*np.sum((y_hat-y_true)**2,axis=0)\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        self.init_weights() ## initialize weights\n",
    "        X = np.insert(X,0,values=1,axis=1) ## appending 1 to all x vectors\n",
    "        \n",
    "        for epoch in range(self.max_epoch):\n",
    "            total_cost = 0\n",
    "            for (x_i,y_i) in zip(X,Y):\n",
    "                self.feed_forward(x_i)\n",
    "                self.backpropagation(y_i)\n",
    "                self.update_weights()\n",
    "                total_cost += self.calculate_cost(self.y_hat[1:],y_i)\n",
    "            print(\"Epoch: \",epoch,total_cost)\n",
    "            if total_cost < 5:\n",
    "                break\n",
    "        return\n",
    "    \n",
    "    def predict(self,X,Y):\n",
    "        correct = 0\n",
    "        sample_number = 0\n",
    "        \n",
    "        X = np.insert(X,0,values=1,axis=1)\n",
    "        \n",
    "        for (x_i,y_i) in zip(X,Y):\n",
    "            self.feed_forward(x_i)\n",
    "            sample_number += 1\n",
    "            \n",
    "            predicted_class = np.argmax(self.y[-1][1:])\n",
    "            actual_class = np.argmax(y_i)\n",
    "            \n",
    "            if predicted_class == actual_class:\n",
    "                correct += 1\n",
    "            else:\n",
    "                print(sample_number,x_i,y_i,actual_class+1,predicted_class+1)\n",
    "        \n",
    "        return correct/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 194.24704028385736\n",
      "Epoch:  1 149.06985364407905\n",
      "Epoch:  2 114.91484728610091\n",
      "Epoch:  3 83.11638804182851\n",
      "Epoch:  4 59.80908657196476\n",
      "Epoch:  5 50.00194596025624\n",
      "Epoch:  6 41.82773707579726\n",
      "Epoch:  7 33.28253490236738\n",
      "Epoch:  8 27.151673752327678\n",
      "Epoch:  9 23.200938084815483\n",
      "Epoch:  10 20.479680218579244\n",
      "Epoch:  11 18.18441502997965\n",
      "Epoch:  12 16.13082347019566\n",
      "Epoch:  13 14.46809662943353\n",
      "Epoch:  14 13.008145851915048\n",
      "Epoch:  15 11.168075587210643\n",
      "Epoch:  16 10.221813736240094\n",
      "Epoch:  17 9.067205572121953\n",
      "Epoch:  18 8.200786269596776\n",
      "Epoch:  19 6.919109521313854\n",
      "Epoch:  20 7.294187022130062\n",
      "Epoch:  21 5.7464280400354255\n",
      "Epoch:  22 5.445498174037877\n",
      "Epoch:  23 5.089425880275462\n",
      "Epoch:  24 4.711045083410885\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()  # min max scaler\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "input_neurons = X_train.shape[1]\n",
    "output_neurons = Y_train.shape[1] \n",
    "\n",
    "model = L_Layer_NN([input_neurons,3,2,output_neurons],lr=1)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test,Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
